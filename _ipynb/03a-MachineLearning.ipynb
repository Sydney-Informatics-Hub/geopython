{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"03a. Machine Learning for Geoscience\"\n",
    "teaching: 90\n",
    "exercises: 30\n",
    "questions:\n",
    "- \"What data science tools and techniques can be used in Python?\"\n",
    "- \"How do I do it?\"\n",
    "objectives:\n",
    "- \"Learn fundamental Machine Learning packages.\"\n",
    "- \"Learn to further explore data.\"\n",
    "keypoints:\n",
    "- \"Applying ML workflows\"\n",
    "- \"Wrangling data.\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some standard Machine Learning tools available in Python packages to analyse some data.\n",
    "\n",
    "We have a dataset (from Butterworth et al. 2016) with a collection of tectonomagmatic parameters associated with the time and location of porphyry copper deposits. We want to determine which of these (if any) parameters are geologically important (or at least statistically significant) in relation to the formation of porphyry coppers.\n",
    "\n",
    "Below is an animation of the tectonomagmatic evolution of the South American plate margin since 150Ma, representing many of the parameters in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](../fig/MullerConvergenceSmall.gif \"segment\")\n",
    "\n",
    "# Start by importing most of the modules we need\n",
    "By convention module loads go at the top of your workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas #For dealing with data structures\n",
    "import numpy as np #Data array manipulation\n",
    "import scipy #Scientific Python, has lots of useful tools\n",
    "import scipy.io #A specific sub-module for input/output of sci data\n",
    "\n",
    "#scikit-learn tools to perform machine learning classification\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#For making pretty figures\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import cm\n",
    "\n",
    "#For easy geographic projections on a map\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "#For dealing with shapefiles\n",
    "import shapefile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Use pandas to load in the machine learning dataset\n",
    "ml_data=pandas.read_csv(\"../data/ml_data_points.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#Print out the dataset so we can see what it looks like\n",
    "ml_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>0 Present day longitude (degrees)</th>\n",
    "      <th>1 Present day latitude (degrees)</th>\n",
    "      <th>2 Reconstructed longitude (degrees)</th>\n",
    "      <th>3 Reconstructed latitude (degrees)</th>\n",
    "      <th>4 Age (Ma)</th>\n",
    "      <th>5 Time before mineralisation (Myr)</th>\n",
    "      <th>6 Seafloor age (Myr)</th>\n",
    "      <th>7 Segment length (km)</th>\n",
    "      <th>8 Slab length (km)</th>\n",
    "      <th>9 Distance to trench edge (km)</th>\n",
    "      <th>...</th>\n",
    "      <th>11 Subducting plate parallel velocity (km/Myr)</th>\n",
    "      <th>12 Overriding plate normal velocity (km/Myr)</th>\n",
    "      <th>13 Overriding plate parallel velocity (km/Myr)</th>\n",
    "      <th>14 Convergence normal rate (km/Myr)</th>\n",
    "      <th>15 Convergence parallel rate (km/Myr)</th>\n",
    "      <th>16 Subduction polarity (degrees)</th>\n",
    "      <th>17 Subduction obliquity (degrees)</th>\n",
    "      <th>18 Distance along margin (km)</th>\n",
    "      <th>19 Subduction obliquity signed (radians)</th>\n",
    "      <th>20 Ore Deposits Binary Flag (1 or 0)</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>-66.28</td>\n",
    "      <td>-27.37</td>\n",
    "      <td>-65.264812</td>\n",
    "      <td>-28.103781</td>\n",
    "      <td>6.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>48.189707</td>\n",
    "      <td>56.08069</td>\n",
    "      <td>2436.30907</td>\n",
    "      <td>2436.30907</td>\n",
    "      <td>...</td>\n",
    "      <td>40.63020</td>\n",
    "      <td>-17.43987</td>\n",
    "      <td>12.20271</td>\n",
    "      <td>102.31471</td>\n",
    "      <td>28.82518</td>\n",
    "      <td>5.67505</td>\n",
    "      <td>15.73415</td>\n",
    "      <td>2269.19769</td>\n",
    "      <td>0.274613</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>-69.75</td>\n",
    "      <td>-30.50</td>\n",
    "      <td>-67.696759</td>\n",
    "      <td>-31.970639</td>\n",
    "      <td>12.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>52.321162</td>\n",
    "      <td>56.09672</td>\n",
    "      <td>2490.68735</td>\n",
    "      <td>2490.68735</td>\n",
    "      <td>...</td>\n",
    "      <td>39.60199</td>\n",
    "      <td>-22.80622</td>\n",
    "      <td>13.40127</td>\n",
    "      <td>115.35820</td>\n",
    "      <td>27.39401</td>\n",
    "      <td>5.78937</td>\n",
    "      <td>13.35854</td>\n",
    "      <td>1823.34107</td>\n",
    "      <td>0.233151</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>-66.65</td>\n",
    "      <td>-27.27</td>\n",
    "      <td>-65.128689</td>\n",
    "      <td>-28.374772</td>\n",
    "      <td>9.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>53.506085</td>\n",
    "      <td>55.77705</td>\n",
    "      <td>2823.54951</td>\n",
    "      <td>2823.54951</td>\n",
    "      <td>...</td>\n",
    "      <td>45.32425</td>\n",
    "      <td>-18.08485</td>\n",
    "      <td>11.27500</td>\n",
    "      <td>100.24282</td>\n",
    "      <td>34.62444</td>\n",
    "      <td>8.97218</td>\n",
    "      <td>19.05520</td>\n",
    "      <td>2269.19769</td>\n",
    "      <td>0.332576</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>-66.61</td>\n",
    "      <td>-27.33</td>\n",
    "      <td>-65.257928</td>\n",
    "      <td>-28.311094</td>\n",
    "      <td>8.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>51.317135</td>\n",
    "      <td>55.90088</td>\n",
    "      <td>2656.71724</td>\n",
    "      <td>2656.71724</td>\n",
    "      <td>...</td>\n",
    "      <td>43.13319</td>\n",
    "      <td>-17.78538</td>\n",
    "      <td>11.72618</td>\n",
    "      <td>101.21965</td>\n",
    "      <td>31.92962</td>\n",
    "      <td>7.42992</td>\n",
    "      <td>17.50782</td>\n",
    "      <td>2269.19769</td>\n",
    "      <td>0.305569</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>298</th>\n",
    "      <td>-71.31</td>\n",
    "      <td>-14.91</td>\n",
    "      <td>-38.398992</td>\n",
    "      <td>-21.934657</td>\n",
    "      <td>151.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>17.739843</td>\n",
    "      <td>53.93117</td>\n",
    "      <td>323.86191</td>\n",
    "      <td>323.86191</td>\n",
    "      <td>...</td>\n",
    "      <td>-3.42257</td>\n",
    "      <td>-17.25992</td>\n",
    "      <td>-22.78837</td>\n",
    "      <td>8.88338</td>\n",
    "      <td>-7.68381</td>\n",
    "      <td>-40.99490</td>\n",
    "      <td>40.85864</td>\n",
    "      <td>3378.69739</td>\n",
    "      <td>-0.713118</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>299</th>\n",
    "      <td>-70.61</td>\n",
    "      <td>-17.25</td>\n",
    "      <td>-37.243172</td>\n",
    "      <td>-24.160112</td>\n",
    "      <td>145.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>11.744395</td>\n",
    "      <td>53.94534</td>\n",
    "      <td>163.59542</td>\n",
    "      <td>163.59542</td>\n",
    "      <td>...</td>\n",
    "      <td>-2.26253</td>\n",
    "      <td>14.87833</td>\n",
    "      <td>0.05195</td>\n",
    "      <td>2.36178</td>\n",
    "      <td>-23.78566</td>\n",
    "      <td>-38.97366</td>\n",
    "      <td>84.32944</td>\n",
    "      <td>3160.06366</td>\n",
    "      <td>-1.471826</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>300</th>\n",
    "      <td>-76.13</td>\n",
    "      <td>-11.60</td>\n",
    "      <td>-43.993914</td>\n",
    "      <td>-16.965040</td>\n",
    "      <td>101.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>35.880790</td>\n",
    "      <td>54.85460</td>\n",
    "      <td>1190.90698</td>\n",
    "      <td>1190.90698</td>\n",
    "      <td>...</td>\n",
    "      <td>40.29418</td>\n",
    "      <td>-31.96652</td>\n",
    "      <td>41.93348</td>\n",
    "      <td>71.76161</td>\n",
    "      <td>-29.57451</td>\n",
    "      <td>-38.50603</td>\n",
    "      <td>22.39762</td>\n",
    "      <td>4093.90633</td>\n",
    "      <td>-0.390912</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<p>301 rows Ã— 21 columns</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 21 columns (python (usually) counts from 0) representing different parameters. Some of these parameters may be useful for us. Some are not. The final column contains a binary flag representing whether there is a known porphyry copper deposit at that location or not. The \"non-deposits\" are required to train our Machine Learning classifier what a porphyry deposit looks like, and also, what a porphyry deposit doesn't look like!\n",
    "\n",
    "### Now let's perform our machine learning binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change data format to numpy array for easy manipulation\n",
    "ml_data_np=ml_data.values\n",
    "\n",
    "#Set the indices of the parameters (features) to include in the ML\n",
    "params=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "# Alternatively try any 4 features you'd like to include!\n",
    "#params=[6,9,14,17] \n",
    "\n",
    "\n",
    "#Save the number of parameters we have chosen\n",
    "datalength=len(params)\n",
    "\n",
    "#Normalise the data for Machine Learning\n",
    "ml_data_norm=preprocessing.scale(ml_data_np[:,params])\n",
    "\n",
    "#Create a 'feature vector' and a 'target classification vector'\n",
    "features=ml_data_norm\n",
    "targets=ml_data_np[:,20]\n",
    "\n",
    "#Print out some info about our final dataset\n",
    "print(\"Shape of ML data array: \", ml_data_norm.shape)\n",
    "print(\"Positive (deposits) examples: \",np.shape(ml_data_np[ml_data_np[:,20]==1,:]))\n",
    "print(\"Negative (non-deposits) examples: \",np.shape(ml_data_np[ml_data_np[:,20]==0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ('Shape of ML data array: ', (301, 21))\n",
    "    ('Positive (deposits) examples: ', (147, 21))\n",
    "    ('Negative (non-deposits) examples: ', (154, 21))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Make the classifiers')\n",
    "\n",
    "print('Random Forest...')\n",
    "#create and train the random forest\n",
    "#multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
    "#n_estimators use between 64-128 doi: 10.1007/978-3-642-31537-4_13\n",
    "rf = RandomForestClassifier(n_estimators=128, n_jobs=1,class_weight=None)\n",
    "rf.fit(features,targets)\n",
    "print(\"Done RF\")\n",
    "\n",
    "scores = cross_val_score(rf, features,targets, cv=10)\n",
    "print(\"RF Scores: \",scores)\n",
    "print(\"SCORE Mean: %.2f\" % np.mean(scores), \"STD: %.2f\" % np.std(scores), \"\\n\")\n",
    "\n",
    "print(\"Targets (expected result):\")\n",
    "print(targets)\n",
    "\n",
    "print(\"Prediction (actual result):\")\n",
    "print(rf.predict(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Make the classifiers\n",
    "    Random Forest...\n",
    "    Done RF\n",
    "    ('RF Scores: ', array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))\n",
    "    ('SCORE Mean: 1.00', 'STD: 0.00', '\\n')\n",
    "    Targets (expected result):\n",
    "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "    Prediction (actual result):\n",
    "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "     1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    "     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of labels for our chosen features\n",
    "paramColumns=np.array(ml_data.columns)\n",
    "paramLabels=paramColumns[params].tolist()\n",
    "\n",
    "#Create a new figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#Plot the bar graph\n",
    "rects=ax.barh(np.arange(0, datalength, step=1),rf.feature_importances_)\n",
    "\n",
    "#Label the axes\n",
    "ax.set_yticks(np.arange(0, datalength, step=1))\n",
    "ax.set_yticklabels(paramLabels,rotation=90)\n",
    "ax.set_xlabel('Feature Importance')\n",
    "\n",
    "#Print the feature importance to compare with plot\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "print(\"Importance \\t Feature\")\n",
    "for i,label in enumerate(paramLabels):\n",
    "    print(\"%1.3f \\t\\t %s\" % (rf.feature_importances_[i],label))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Importance \t Feature\n",
    "    0.014 \t\t 0 Present day longitude (degrees)\n",
    "    0.013 \t\t 1 Present day latitude (degrees)\n",
    "    0.049 \t\t 2 Reconstructed longitude (degrees)\n",
    "    0.014 \t\t 3 Reconstructed latitude (degrees)\n",
    "    0.054 \t\t 4 Age (Ma)\n",
    "    0.000 \t\t 5 Time before mineralisation (Myr)\n",
    "    0.040 \t\t 6 Seafloor age (Myr)\n",
    "    0.018 \t\t 7 Segment length (km)\n",
    "    0.025 \t\t 8 Slab length (km)\n",
    "    0.032 \t\t 9 Distance to trench edge (km)\n",
    "    0.022 \t\t 10 Subducting plate normal velocity (km/Myr)\n",
    "    0.019 \t\t 11 Subducting plate parallel velocity (km/Myr)\n",
    "    0.027 \t\t 12 Overriding plate normal velocity (km/Myr)\n",
    "    0.022 \t\t 13 Overriding plate parallel velocity (km/Myr)\n",
    "    0.019 \t\t 14 Convergence normal rate (km/Myr)\n",
    "    0.013 \t\t 15 Convergence parallel rate (km/Myr)\n",
    "    0.016 \t\t 16 Subduction polarity (degrees)\n",
    "    0.031 \t\t 17 Subduction obliquity (degrees)\n",
    "    0.012 \t\t 18 Distance along margin (km)\n",
    "    0.015 \t\t 19 Subduction obliquity signed (radians)\n",
    "    0.546 \t\t 20 Ore Deposits Binary Flag (1 or 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](../fig/fig-02ML-featimp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we can measure the tectonomagmatic properties at some point. Based on our trained classifier we can predict a probability that porphyry copper deposits have formed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the trained ML to our gridded data to determine the probabilities at each of the points\n",
    "print('RF...')\n",
    "pRF=np.array(rf.predict_proba(features))\n",
    "print(\"Done RF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    RF...\n",
    "    Done RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "filename=\"../data/topodata.nc\"\n",
    "data = scipy.io.netcdf.netcdf_file(filename,'r')\n",
    "\n",
    "data.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    OrderedDict([('X', <scipy.io.netcdf.netcdf_variable at 0x7fec3cd4f0d0>),\n",
    "                 ('Y', <scipy.io.netcdf.netcdf_variable at 0x7fec3cd4f450>),\n",
    "                 ('elev', <scipy.io.netcdf.netcdf_variable at 0x7fec3cd4f590>)])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topoX=data.variables['X'][:]\n",
    "topoY=data.variables['Y'][:]\n",
    "topoZ=np.array(data.variables['elev'][:])\n",
    "\n",
    "#Some file types and readers (like netcdf) can actually change the data directly on disk\n",
    "#Good practice, is to close the file when done (for safety and memory saving)\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Make a figure object\n",
    "plt.figure()\n",
    "\n",
    "#Get the axes of the current figure, for manipulation\n",
    "ax = plt.gca()\n",
    "\n",
    "#Put down the main topography dataset\n",
    "im=ax.imshow(topoZ,vmin=-5000,vmax=1000,extent=[0,360,-90,90],origin='upper',aspect=1,cmap=cm.gist_earth)\n",
    "\n",
    "#Make a colorbar\n",
    "cbar=plt.colorbar(im,fraction=0.025,pad=0.05,ticks=[-5000,0, 1000],extend='both')\n",
    "cbar.set_label('Height \\n ASL \\n (m)', rotation=0)\n",
    "\n",
    "#Clean up the default axis ticks\n",
    "plt.yticks([-90,-45,0,45,90])\n",
    "plt.xticks([0,90,180,270,360])\n",
    "\n",
    "#Put labels on the figure\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "#Put a title on it\n",
    "plt.title(\"Bathymetry and Topography of the World \\n (ETOPO5 2020)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](../fig/fig-02ML-topo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loops plotting shapefiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in plate polygons for plotting\n",
    "topologyFile='../data/topology_platepolygons_0.00Ma.shp'\n",
    "\n",
    "#read in the file\n",
    "shapeRead = shapefile.Reader(topologyFile)\n",
    "\n",
    "#And save out some of the shape file attributes\n",
    "recs    = shapeRead.records()\n",
    "shapes  = shapeRead.shapes()\n",
    "fields  = shapeRead.fields\n",
    "Nshp    = len(shapes)\n",
    "\n",
    "for i, nshp in enumerate(range(Nshp)):\n",
    "    #if nshp!=35 and nshp!=36 and nshp!=23:\n",
    "    #These are the plates that cross the dateline and cause \n",
    "        #banding errors\n",
    "        polygonShape=shapes[nshp].points\n",
    "        poly=np.array(polygonShape)\n",
    "        plt.plot(poly[:,0], poly[:,1], c='k',zorder=1)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](../fig/fig-02ML-plates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a prettier map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "###Set up the figure\n",
    "fig = plt.figure(figsize=(16,12),dpi=150)\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent([-85, -30, -55, 10])\n",
    "ax.coastlines('50m', linewidth=0.8)\n",
    "\n",
    "###Add the map grid lines and format them\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='-')\n",
    "\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib import colorbar, colors\n",
    "\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_left = True\n",
    "gl.ylabels_right = False\n",
    "gl.xlines = False\n",
    "gl.ylines = False\n",
    "gl.xlocator = mticker.FixedLocator([-75,-60, -45,-30])\n",
    "gl.ylocator = mticker.FixedLocator([-60, -45, -30, -15, 0,15])\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "#gl.xlabel_style = {'size': 15, 'color': 'gray'}\n",
    "#gl.xlabel_style = {'color': 'black', 'weight': 'normal'}\n",
    "\n",
    "print(\"Made base map\")\n",
    "\n",
    "###Plot a topography underlay image\n",
    "#Make a lat lon grid to fit the topo grid\n",
    "lons, lats = np.meshgrid(topoX,topoY)\n",
    "im1=ax.pcolormesh(lons,lats,topoZ, shading=\"flat\",cmap=plt.cm.gist_earth,transform=ccrs.PlateCarree())              \n",
    "cbar=plt.colorbar(im1, ax=ax, orientation=\"horizontal\", pad=0.02, fraction=0.05, shrink=0.2,extend='both')\n",
    "cbar.set_label('Topography (m)')\n",
    "\n",
    "print(\"Added topo\")\n",
    "\n",
    "###Plot shapefile polygon outlines\n",
    "#Load in plate polygons for plotting\n",
    "topologyFile='../data/topology_platepolygons_0.00Ma.shp'\n",
    "\n",
    "#read in the file\n",
    "shapeRead = shapefile.Reader(topologyFile)\n",
    "\n",
    "#And save out some of the shape file attributes\n",
    "recs    = shapeRead.records()\n",
    "shapes  = shapeRead.shapes()\n",
    "fields  = shapeRead.fields\n",
    "Nshp    = len(shapes)\n",
    "\n",
    "for i, nshp in enumerate(range(Nshp)):\n",
    "    if nshp!=35 and nshp!=36 and nshp!=23:\n",
    "    #These are the plates that cross the dateline and cause \n",
    "        #banding errors\n",
    "        polygonShape=shapes[nshp].points\n",
    "        poly=np.array(polygonShape)\n",
    "        xh=poly[:,0]\n",
    "        yh=poly[:,1]\n",
    "        ax.plot(xh, yh, c='w',zorder=1)\n",
    "\n",
    "print(\"Added shapes\")\n",
    "        \n",
    "###Plot the ore deposit probability\n",
    "xh = ml_data_np[ml_data_np[:,-1]==1,0]\n",
    "yh= ml_data_np[ml_data_np[:,-1]==1,1]\n",
    "l2 = ax.scatter(xh, yh, 500, marker='.',c=pRF[:147,1],cmap=plt.cm.copper,zorder=3,transform=ccrs.PlateCarree(),vmin=0,vmax=1)\n",
    "#l2 = pmap.scatter(xh, yh, 20, marker='.',edgecolor='dimgrey',linewidth=0.5,c=pRF[:147,1],cmap=plt.cm.copper,zorder=3)\n",
    "cbar=fig.colorbar(l2, ax=ax, orientation=\"horizontal\", pad=0.05, fraction=0.05, shrink=0.2,ticks=[0,0.5,1.0])\n",
    "l2.set_clim(-0.1, 1.1)\n",
    "cbar.set_label('Prediction Probability (%)')\n",
    "\n",
    "###Plot the ore deposit Age\n",
    "xh=ml_data_np[ml_data_np[:,-1]==1,0]\n",
    "yh = ml_data_np[ml_data_np[:,-1]==1,1]\n",
    "l2 = ax.scatter(xh, yh, 50, marker='.',c=ml_data_np[ml_data_np[:,-1]==1,4],cmap=plt.cm.hsv,zorder=3)\n",
    "cbar=fig.colorbar(l2, ax=ax, orientation=\"horizontal\", pad=0.1, fraction=0.05, shrink=0.2,extend='max',ticks=[0,50,100,150])\n",
    "l2.set_clim(0, 170)\n",
    "cbar.set_label('Age of Deposit (Ma)')\n",
    "\n",
    "print(\"Added deposit probability\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Made base map\n",
    "Added topo\n",
    "Added shapes\n",
    "Added deposit probability\n",
    "```\n",
    "\n",
    "![png](../fig/fig-02ML-porphyry.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Do the same analysis but using a different Machine Learning algorithm for your classification. You can use this as a guide for picking a good classification algorithm [https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html). \n",
    "Present your results on a map, and compare it with the Random Forest method. \n",
    "\n",
    "# Datasets\n",
    "\n",
    "#### Topography/Bathymetry\n",
    "WORLDBATH: ETOPO5 5x5 minute Navy bathymetry. http://iridl.ldeo.columbia.edu/SOURCES/.NOAA/.NGDC/.ETOPO5/\n",
    "    \n",
    "#### ML dataset\n",
    "Butterworth et al 2016 https://doi.org/10.1002/2016TC004289\n",
    "\n",
    "#### Shapefile plate polygons\n",
    "GPlates2.0. https://www.gplates.org/"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md,ipynb",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
